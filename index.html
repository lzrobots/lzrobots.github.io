<!doctype html> 
<html lang="en"> 
<head> 
<meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> 
<title> Li Zhang </title> 
<meta name="HandheldFriendly" content="True"> 
<meta name="MobileOptimized" content="320"> 
<link rel="stylesheet" href="css/bootstrap.min.css"> 
<link rel="stylesheet" href="css/style.css"> 
<link rel="shortcut icon" type="image/png" href="https://www.campaign.ox.ac.uk/image/oxford-logo.png"> 
</head> 

<body> 
<div id="home" class="container-fluid"> 

<div class="row-center"> 
<h1>Li Zhang</h1> 
<p>Tenure-track Professor
</br>School of Data Science, Fudan University</p> 
<a href="mailto:lizhangfd@fudan.edu.cn">email</a> /
<a href="https://scholar.google.com/citations?user=-wOTCE8AAAAJ&hl=en" target="_blank">google scholar</a>
</div> 

<hr> 
<div class="row"> 
<p> I am a tenure-track Professor at the School of Data Science, Fudan University. Previously, I was a Research Scientist at Samsung AI Center Cambridge, and a Postdoctoral Researcher at the Department of Engineering Science, University of Oxford, under the supervision of professor <a href="https://scholar.google.com/citations?user=kPxa2w0AAAAJ&hl=en" target="_blank">Philip H.S. Torr</a> and professor <a href="https://scholar.google.com/citations?user=UZ5wscMAAAAJ&hl=en" target="_blank">Andrew Zisserman</a>. Prior to joining Oxford, I read my PhD in computer science under the supervision of professor <a href="https://scholar.google.com/citations?user=MeS5d4gAAAAJ&hl=en" target="_blank">Tao Xiang</a> at Queen Mary University of London.
</p> 
<br> 
<p> My general research interests cover the broad area of machine learning and artificial intelligence, with special emphasis on building intelligent systems for <span class="papertitle">autonomous driving</span> and <span class="papertitle">generalist embodied agent</span>.
</p> 
</div> 


<br> 
<div class="row"> 
<h4> To Prospective Students </h4> 
<p>
	If you are highly creative, have top grades/coding skill and interested in joining my group please do not hesitate to send me your CV and transcripts of grades.
	<br> 
	Make sure you are super <font color="#FF0000">enthusiastic</font> about AI research.
</p> 

</div> 


<hr> <div class="row"> 
<h2> News </h2> 
<br> 

<li> Five papers (2 Spotlights and 3 Posters) to appear in NeurIPS 2024.</li> 	
<li> I will be serving as an Area Chair for <a href="https://cvpr.thecvf.com" target="_blank">CVPR 2025</a>.</li> 
<!-- <li> Our work <a href="https://arxiv.org/abs/2404.14671" target="_blank">LaneCorrect</a> is accepted by IJCV.</li> -->
<li> Three papers to appear in ECCV 2024.</li> 	
<li> Our work <a href="https://github.com/fudan-zvg/SETR" target="_bla nk">SETR</a> is accepted by IJCV.</li>
<li> One paper to appear in IROS 2024 as oral presentation. </li> 
<li> Two papers are accepted by IEEE RAL. </li>
<li> I will be serving as an Area Chair for <a href="https://nips.cc" target="_blank">NeurIPS 2024</a>.</li> 
<li> Our work <a href="https://github.com/fudan-zvg/SOFT" target="_blank">SOFT</a> is accepted by IJCV.</li>
<li> Three papers to appear in ICLR 2024.</li> 	
<li> Appointed as Associate Editor (AE) for Pattern Recognition.</li> 	
<li> Two papers (1 Oral and 1 Poster) to appear in AAAI 2024.</li> 	
<li> Two papers (1 Oral and 1 Poster) to appear in ICCV 2023.</li> 
<li> I will be serving as an Area Chair for <a href="https://cvpr.thecvf.com/Conferences/2024" target="_blank">CVPR 2024</a>.</li> 
<li> One paper to appear in IROS 2023.</li> 
<li> One paper is accepted by Machine Vision and Applications.</li> 
<li> I will be serving as an Area Chair for <a href="https://nips.cc" target="_blank">NeurIPS 2023</a>.</li> 
<li> Two papers (1 Highlight and 1 Poster) to appear in CVPR 2023.</li> 
<li> Two papers to appear in ICLR 2023.</li> 
<li> <font color="#FF0000">Call for papers!</font> We are orgnising a <a href="https://e2ead.github.io/2023.html" target="_blank">CVPR 2023 workshop</a> on End-to-End Autonomous Driving: Perception, Prediction, Planning and Simulation.</li> 
<li> One paper (Oral) to appear in AAAI 2023.</li> 
<li> I will be serving as an Area Chair for <a href="https://cvpr2023.thecvf.com" target="_blank">CVPR 2023</a>.</li> 
<li> I will be talking at <a href="https://ccai.caai.cn/#guest" target="_blank">CCAI</a> 2022 and <a href="http://www.prcv.cn" target="_blank">PRCV</a> 2022.</li> 
<li> One paper (Spotlight) to appear in NeurIPS 2022.</li> 
<li> Our work <a href="https://github.com/fudan-zvg/DGMN2" target="_blank">DGMN</a> is accepted by IEEE TPAMI.</li>
<li> Four papers to appear in ECCV 2022.</li> 
<li> Our DeepInteraction is ranked 1st at the <span class="distinction">nuScenes 3D detection</span> <a href="https://nuscenes.org/object-detection?externalData=all&mapData=all&modalities=Any" target="_blank">leaderboard</a>.</li>
<li> Our work SiamMask is accepted by IEEE TPAMI.</li>
<li> One paper to appear in CVPR 2022.</li> 
<li> Our work <a href="https://fudan-zvg.github.io/SETR/" target="_blank">SETR</a> is ranked second at the <a href="https://www.paperdigest.org/2022/02/most-influential-cvpr-papers-2022-02/" target="_blank">most influential CVPR papers</a>.</li>
<li> Two papers (1 Spotlight and 1 Poster) to appear in NeurIPS 2021.</li> 
<!-- <li> Three papers to appear in ICCV 2021.</li> 
<li> Two papers are accepted by IEEE TIP.</li>
<li> One paper is accepted by IEEE TPAMI.</li>
<li> Elected to the <span class="distinction">Shanghai Science & Technology 35 Under 35</span>.</li>
<li> Four papers to appear in CVPR 2021.</li>  -->
<!-- <li> Rank 1st on the test set of <a href="http://sceneparsing.csail.mit.edu/eval/leaderboard.php" target="_blank">MIT Scene Parsing Benchmark ADE20K</a>.</li> 
<li> One paper to appear in AAAI 2021.</li> 
<li> Two papers (1 Oral and 1 Poster) to appear in ACCV 2020.</li> 
<li> One paper to appear in ACM MM 2020.</li> 
<li> Three papers (1 Spotlight and 2 Posters) to appear in ECCV 2020.</li> 
<li> Our team (SAIC, Cambridge) win 3rd (Seen) and 6th (Unseen) in <a href="https://epic-kitchens.github.io/2020-55.html#results" target="_blank">EPIC-Kitchens challenges 2020</a>.</li>  
<li> Four papers (1 Oral and 3 Posters) to appear in CVPR 2020.</li>  -->
</div> 

<hr> <div class="row"> 
<h2> Preprint </h2> 
<br> 
<ul> 

<li> <span class="papertitle">DeepInteraction++: Multi-Modality Interaction for Autonomous Driving,</span>
<br> Zeyu Yang, Nan Song, Wei Li, Xiatian Zhu, Li Zhang, Philip HS Torr,
<br> arXiv preprint, 2024
</li> 


<li> <span class="papertitle">Diffusion<sup>2</sup>: Dynamic 3D Content Generation via Score Composition of Orthogonal Diffusion Models,</span>
<br> Zeyu Yang, Zijie Pan, Chun Gu, Li Zhang,
<br> arXiv preprint, 2024
[<a href="https://github.com/fudan-zvg/diffusion-square" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">Data Interpreter: An LLM Agent for Data Science,</span>
<br> Sirui Hong, Yizhang Lin, Bang Liu, Bangbang Liu, Binhao Wu, Danyang Li, Jiaqi Chen, Jiayi Zhang, Jinlin Wang, Li Zhang, et al.
<br> arXiv preprint, 2024
[<a href="https://github.com/geekan/MetaGPT" target="_blank">code</a>]
</li> 

<li> <span class="papertitle">Translating Images to Road Network: A Sequence-to-Sequence Perspective,</span>
<br> Jiachen Lu, Renyuan Peng, Xinyue Cai, Hang Xu, Feng Wen, Wei Zhang, Li Zhang,
<br> arXiv preprint, 2024
[<a href="https://github.com/fudan-zvg/RoadNet" target="_blank">code</a>]
</li> 

	
<li> <span class="papertitle">S-NeRF++: Autonomous Driving Simulation via Neural Reconstruction and Generation,</span>
<br> Yurui Chen, Junge Zhang, Ziyang Xie, Wenye Li, Feihu Zhang, Jiachen Lu, Li Zhang,
<br> arXiv preprint, 2024
[<a href="https://arxiv.org/abs/2402.02112" target="_blank">paper</a>]
[<a href="https://github.com/fudan-zvg/S-NeRF" target="_blank">code</a>]
</li> 

	
<li> <span class="papertitle">SeaFormer++: Squeeze-enhanced Axial Transformer for Mobile Visual Recognition,</span>
<br> Qiang Wan, Zilong Huang, Jiachen Lu, Gang Yu, Li Zhang,
<br> arXiv preprint, 2024
[<a href="https://arxiv.org/abs/2301.13156" target="_blank">paper</a>]
</li> 


<li> <span class="papertitle">Neural 3D decoding for human vision diagnosis,</span>
<br> Li Zhang, Yuankun Yang, Ziyang Xie, Zhiyuan Yuan, Jianfeng Feng, Xiatian Zhu, Yu-Gang Jiang,
<br> arXiv preprint, 2024
[<a href="https://arxiv.org/abs/2405.15239" target="_blank">paper</a>]
</li> 

<li> <span class="papertitle">Urban Scene Diffusion through Semantic Occupancy Map,</span>
<br> Junge Zhang, Qihang Zhang, Li Zhang, Ramana Rao Kompella, Gaowen Liu, Bolei Zhou,
<br> arXiv preprint, 2024
[<a href="https://metadriverse.github.io/urbandiff/" target="_blank">project page</a>]
[<a href="https://arxiv.org/abs/2403.11697" target="_blank">paper</a>]
</li> 

<li> <span class="papertitle">From Summary to Action: Enhancing Large Language Models for Complex Tasks with Open World APIs,</span>
<br> Yulong Liu, Yunlong Yuan, Chunwei Wang, Jianhua Han, Yongqiang Ma, Li Zhang, Nanning Zheng, Hang Xu,
<br> arXiv preprint, 2024
[<a href="https://arxiv.org/abs/2402.18157" target="_blank">paper</a>]
</li> 


<li> <span class="papertitle">Fast Dynamic 3D Object Generation from a Single-view Video,</span>
<br> Zijie Pan, Zeyu Yang, Xiatian Zhu, Li Zhang,
<br> arXiv preprint, 2024
[<a href="https://fudan-zvg.github.io/Efficient4D/" target="_blank">project page</a>]
[<a href="https://github.com/fudan-zvg/Efficient4D" target="_blank">code</a>]
</li> 

<li> <span class="papertitle">Harnessing Diffusion Models for Visual Perception with Meta Prompts,</span>
<br> Qiang Wan, Zilong Huang, Bingyi Kang, Jiashi Feng, Li Zhang,
<br> arXiv preprint, 2023
[<a href="https://github.com/fudan-zvg/meta-prompts" target="_blank">code</a>]
</li> 

	
<li> <span class="papertitle">Periodic Vibration Gaussian: Dynamic Urban Scene Reconstruction and Real-time
Rendering,</span>
<br> Yurui Chen, Chun Gu, Junzhe Jiang, Xiatian Zhu, Li Zhang,
<br> arXiv preprint, 2023
[<a href="https://fudan-zvg.github.io/PVG/" target="_blank">project page</a>]
[<a href="https://github.com/fudan-zvg/PVG" target="_blank">code</a>]
</li> 



<li> <span class="papertitle">Preconditioned Score-based Generative Models,</span>
<br> Hengyuan Ma, Li Zhang, Xiatian Zhu, Jianfeng Feng,
<br> arXiv preprint, 2023
[<a href="https://arxiv.org/abs/2302.06504" target="_blank">paper</a>]
[<a href="https://github.com/fudan-zvg/PDS" target="_blank">code</a>]
</li> 


<br> 
	
<h2> Publications </h2> 
<br> 
<ul> 

<li> <span class="papertitle">Tetrahedron Splatting for 3D Generation,</span>
<br> Chun Gu, Zeyu Yang, Zijie Pan, Xiatian Zhu, Li Zhang,
<br> NeurIPS 2024 <span class="distinction">(Spotlight)</span> 
[<a href="https://github.com/fudan-zvg/tet-splatting" target="_blank">code</a>]
</li> 

<li> <span class="papertitle">SlowFocus: Enhancing Fine-grained Temporal Understanding in Video LLM,</span>
<br> Ming Nie, Dan Ding, Chunwei Wang, Yuanfan Guo, Jianhua Han, Hang Xu, Li Zhang,
<br> NeurIPS 2024
</li> 

<li> <span class="papertitle">DeMo: Decoupling Motion Forecasting into Directional Intentions and Dynamic States,</span>
<br> Bozhou Zhang, Nan Song, Li Zhang,
<br> NeurIPS 2024
</li> 

<li> <span class="papertitle">DG-SLAM: Robust Dynamic Gaussian Splatting SLAM with Hybrid Pose Optimization,</span>
<br> Yueming Xu, Haochen Jiang, Zhongyang Xiao, Jianfeng Feng, Li Zhang,
<br> NeurIPS 2024
</li> 

<li> <span class="papertitle">Motion Forecasting in Continuous Driving,</span>
<br> Nan Song, Bozhou Zhang, Xiatian Zhu, Li Zhang,
<br> NeurIPS 2024 <span class="distinction">(Spotlight)</span> 
</li> 


<!-- <li> <span class="papertitle">LaneCorrect: Self-supervised Lane Detection,</span>
<br> Ming Nie, Xinyue Cai, Hang Xu, Li Zhang,
<br> IJCV 2024
[<a href="https://arxiv.org/abs/2404.14671" target="_blank">paper</a>]
</li>  -->

<li> <span class="papertitle">Reason2Drive: Towards Interpretable and Chain-based Reasoning for Autonomous
Driving,</span>
<br> Ming Nie, Renyuan Peng, Chunwei Wang, Xinyue Cai, Jianhua Han, Hang Xu, Li Zhang,
<br> ECCV 2024
[<a href="https://github.com/fudan-zvg/reason2drive" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">WoVoGen: World Volume-aware Diffusion for Controllable Multi-camera Driving Scene Generation,</span>
<br> Jiachen Lu, Ze Huang, Jiahui Zhang, Zeyu Yang, Li Zhang,
<br> ECCV 2024
[<a href="https://github.com/fudan-zvg/WoVoGen" target="_blank">code</a>]
</li> 

<li> <span class="papertitle">Relightable 3D Gaussian: Real-time Point Cloud Relighting with BRDF Decomposition and Ray Tracing,</span>
<br> Jian Gao, Chun Gu, Youtian Lin, Hao Zhu, Xun Cao, Li Zhang, Yao Yao,
<br> ECCV 2024
[<a href="https://nju-3dv.github.io/projects/Relightable3DGaussian/" target="_blank">project page</a>]
[<a href="https://github.com/NJU-3DV/Relightable3DGaussian" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">Vision Transformers: From Semantic Segmentation to Dense Prediction,</span>
<br> Li Zhang, Jiachen Lu, Sixiao Zheng, Xinxuan Zhao, Xiatian Zhu, Yanwei Fu, Tao Xiang, Jianfeng Feng, Philip H.S. Torr,
<br> IJCV 2024
[<a href="https://arxiv.org/abs/2207.09339" target="_blank">paper</a>]
[<a href="https://github.com/fudan-zvg/SETR" target="_blank">code</a>]
</li> 

<li> <span class="papertitle">OpenOcc: Open Vocabulary 3D Scene Reconstruction via Occupancy Representation,</span>
<br> Haochen Jiang, Yueming Xu, Yihan Zeng, Hang Xu, Wei Zhang, Jianfeng Feng, Li Zhang,
<br> IROS 2024 <span class="distinction">(Oral)</span> 
[<a href="https://arxiv.org/abs/2403.11796" target="_blank">paper</a>]
</li> 


<li> <span class="papertitle">RoDyn-SLAM: Robust Dynamic Dense RGB-D SLAM with Neural Radiance Fields,</span>
<br> Haochen Jiang, Yueming Xu, Kejie Li, Jianfeng Feng, Li Zhang,
<br> IEEE Robotics and Automation Letters (RA-L), 2024
</li> 

<li> <span class="papertitle">A Hybrid Approach for Cross-modality Pose Estimation Between Image and Point Cloud,</span>
<br> Ze Huang, Li Sun, Qibin He, Zhongyang Xiao, Xinhui Bai, Hongyuan Yuan, Song-Zhi Su, Li Zhang, 
<br> IEEE Robotics and Automation Letters (RA-L), 2024
</li> 
	
<li> <span class="papertitle">Softmax-free Linear Transformers,</span>
<br> Jiachen Lu, Junge Zhang, Xiatian Zhu, Jianfeng Feng, Tao Xiang, Li Zhang, 
<br> IJCV 2024
[<a href="https://arxiv.org/abs/2207.03341" target="_blank">paper</a>]
[<a href="https://github.com/fudan-zvg/SOFT" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting,</span>
<br> Zeyu Yang, Hongye Yang, Zijie Pan, Li Zhang,
<br> ICLR 2024
[<a href="https://fudan-zvg.github.io/4d-gaussian-splatting/" target="_blank">project page</a>]
[<a href="https://github.com/fudan-zvg/4d-gaussian-splatting" target="_blank">code</a>]
</li> 
	
<li> <span class="papertitle">Enhancing High-Resolution 3D Generation through Pixel-wise Gradient Clipping,</span>
<br> Zijie Pan, Jiachen Lu, Xiatian Zhu, Li Zhang,
<br> ICLR 2024
[<a href="https://fudan-zvg.github.io/PGC-3D/" target="_blank">project page</a>]
[<a href="https://github.com/fudan-zvg/PGC-3D" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">Consistent4D: Consistent 360 Dynamic Object Generation from Monocular Video,</span>
<br> Yanqin Jiang, Li Zhang, Jin Gao, Weiming Hu, Yao Yao,
<br> ICLR 2024
[<a href="https://consistent4d.github.io" target="_blank">project page</a>]
[<a href="https://github.com/yanqinJiang/Consistent4D" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">S-Agents: Self-organizing Agents in Open-ended Environments,</span>
<br> Jiaqi Chen, Yuxian Jiang, Jiachen Lu, Li Zhang,
<br> ICLR workshop on Large Language Model (LLM) Agents, 2024
[<a href="https://arxiv.org/abs/2402.04578" target="_blank">paper</a>]
[<a href="https://github.com/fudan-zvg/S-Agents" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">NeRF-LiDAR: Generating Realistic LiDAR Point Clouds with Neural Radiance Fields,</span>
<br> Junge Zhang, Feihu Zhang, Shaochen Kuang, Li Zhang,
<br> AAAI 2024 <span class="distinction">(Oral)</span> 
[<a href="https://github.com/fudan-zvg/NeRF-LiDAR" target="_blank">code</a>]
</li> 	

	
<li> <span class="papertitle">LaneGraph2Seq: Lane Topology Extraction with Language Model via Vertex-Edge Encoding and Connectivity Enhancement,</span>
<br> Renyuan Peng, Xinyue Cai, Hang Xu, Jiachen Lu, Feng Wen, Wei Zhang, Li Zhang,
<br> AAAI 2024
[<a href="https://github.com/fudan-zvg/RoadNet" target="_blank">code</a>]	
</li> 	


	
<li> <span class="papertitle">Translating Images to Road Network: A Non-Autoregressive Sequence-to-Sequence Approach,</span>
<br> Jiachen Lu, Renyuan Peng, Xinyue Cai, Hang Xu, Hongyang Li, Feng Wen, Wei Zhang, Li Zhang,
<br> ICCV 2023 <span class="distinction">(Oral)</span> 
[<a href="https://github.com/fudan-zvg/RoadNet" target="_blank">code</a>]
</li> 	

<li> <span class="papertitle">PARTNER: Level up the Polar Representation for LiDAR 3D Object Detection,</span>
<br> Ming Nie, Yujing Xue, Chunwei Wang, Chaoqiang Ye, Hang Xu, Xinge Zhu, Qingqiu Huang, Michael Bi Mi, Xinchao Wang, Li Zhang,
<br> ICCV 2023 
[<a href="https://github.com/fudan-zvg/PARTNER" target="_blank">code</a>]
</li> 	

<li> <span class="papertitle">Persistent Object Identification Leveraging Non-Visual Markers,</span>
<br> Michael PJ Camilleri, Li Zhang, Rasneer S Bains, Andrew Zisserman, Christopher KI Williams,
<br> Machine Vision and Applications 2023 
</li>


<li> <span class="papertitle">SUIT: Learning Significance-guided Information for 3D Temporal Detection,</span>
<br> Zheyuan Zhou, Jiachen Lu, Yihan Zeng, Hang Xu, Li Zhang,
<br> IROS 2023 <span class="distinction">(Oral)</span> 
</li> 	

	
<li> <span class="papertitle">Generative Semantic Segmentation,</span>
<br> Jiaqi Chen, Jiachen Lu, Xiatian Zhu, Li Zhang,
<br> CVPR 2023 
[<a href="https://github.com/fudan-zvg/GSS" target="_blank">code</a>]
</li> 		
	
<li> <span class="papertitle">FAME-ViL: Multi-Tasking Vision-Language Model for Heterogeneous Fashion Tasks,</span>
<br> Xiao Han, Xiatian Zhu, Licheng Yu, Li Zhang, Yi-Zhe Song, Tao Xiang,
<br> CVPR 2023 <span class="distinction">(Highlight)</span> 
[<a href="https://github.com/BrandonHanx/FAME-ViL" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">S-NeRF: Neural Radiance Fields for Street Views,</span>
<br> Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang,
<br> ICLR 2023 
[<a href="https://ziyang-xie.github.io/s-nerf/" target="_blank">project page</a>]
[<a href="https://github.com/fudan-zvg/S-NeRF" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">SeaFormer: Squeeze-enhanced Axial Transformer for Mobile Semantic Segmentation,</span>
<br> Qiang Wan, Jiachen Lu, Zilong Huang, Gang Yu, Li Zhang,
<br> ICLR 2023 
[<a href="https://arxiv.org/abs/2301.13156" target="_blank">paper</a>]
[<a href="https://github.com/fudan-zvg/SeaFormer" target="_blank">code</a>]	
</li> 


<li> <span class="papertitle">PolarFormer: Multi-camera 3D Object Detection with Polar Transformers,</span>
<br> Yanqin Jiang, Li Zhang, Zhenwei Miao, Xiatian Zhu, Jin Gao, Weiming Hu, Yu-Gang Jiang,
<br> AAAI 2023 <span class="distinction">(Oral)</span> 
[<a href="https://arxiv.org/abs/2206.15398" target="_blank">paper</a>]
[<a href="https://github.com/fudan-zvg/PolarFormer" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">Dynamic Graph Message Passing Network for Visual Recognition,</span>
<br> Li Zhang, Mohan Chen, Anurag Arnab, Xiangyang Xue, Philip H.S. Torr 
<br> IEEE TPAMI 2023
[<a href="https://arxiv.org/abs/2209.09760" target="_blank">paper</a>]
[<a href="https://github.com/fudan-zvg/DGMN2" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">SiamMask: A Framework for Fast Online Object Tracking and Segmentation,</span>
<br> Weiming Hu, Qiang Wang, Li Zhang, Luca Bertinetto, Philip H.S. Torr
<br> TPAMI 2023
[<a href="https://github.com/foolwood/SiamMask" target="_blank">code</a>]
</li> 



<li> <span class="papertitle">ImpDet: Exploring Implicit Fields for 3D Object Detection,</span>
<br> Xuelin Qian, Li Wang, Yi Zhu, Li Zhang, Yanwei Fu, Xiangyang Xue,
<br> WACV 2023
[<a href="https://arxiv.org/abs/2203.17240" target="_blank">paper</a>]
</li> 


<li> <span class="papertitle">Rethinking Local and Global Feature Representation for Dense Prediction,</span>
<br> Mohan Chen, Li Zhang, Rui Feng, Xiangyang Xue, Jianfeng Feng, 
<br> Pattern Recognition 2023
</li> 


<li> <span class="papertitle">DeepInteraction: 3D Object Detection via Modality Interaction,</span>
<br> Zeyu Yang, Jiaqi Chen, Zhenwei Miao, Wei Li, Xiatian Zhu, Li Zhang,
<br> NeurIPS 2022 <span class="distinction">(Spotlight)</span> 
[<a href="https://github.com/fudan-zvg/DeepInteraction" target="_blank">code</a>]
</li> 



<li> <span class="papertitle">When, Where and How does it fail? A Spatial-temporal Visual Analytics Approach for Interpretable Object Detection in Autonomous Driving,</span>
<br> Junhong Wang, Yun Li, Zhaoyu Zhou, Chengshun Wang, Yijie Hou, Li Zhang, Xiangyang Xue, Michael Kamp, Xiaolong (Luke) Zhang, Siming Chen 
<br> IEEE TVCG 2022
</li> 


<li> <span class="papertitle">Learning Ego 3D Representation as Ray Tracing,</span>
<br> Jiachen Lu, Zheyuan Zhou, Xiatian Zhu, Hang Xu, Li Zhang,
<br> ECCV 2022
[<a href="https://github.com/fudan-zvg/Ego3RT" target="_blank">code</a>]
[<a href="https://youtu.be/lMwcGUahlJg" target="_blank">demo</a>]
</li> 


<li> <span class="papertitle">Accelerating Score-based Generative Models with Preconditioned Diffusion Sampling,</span>
<br> Hengyuan Ma, Li Zhang, Xiatian Zhu, Jianfeng Feng,
<br> ECCV 2022
[<a href="https://github.com/fudan-zvg/PDS" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">FashionViL: Fashion-Focused Vision-and-Language Representation Learning,</span>
<br> Xiao Han, Licheng Yu, Xiatian Zhu, Li Zhang, Yi-Zhe Song, and Tao Xiang,
<br> ECCV 2022
[<a href="https://github.com/BrandonHanx/mmf/tree/dev_brandon" target="_blank">code</a>]
</li> 



<li> <span class="papertitle">RCLane: Relay Chain Prediction for Lane Detection,</span>
<br> Shenghua Xu, Xinyue Cai, Bin Zhao, Li Zhang, Hang Xu, Yanwei Fu, Xiangyang Xue,
<br> ECCV 2022
</li> 



<li> <span class="papertitle">ONCE-3DLanes: Building Monocular 3D Lane Detection,</span>
<br> Fan Yan, Ming Nie, Xinyue Cai, Jianhua Han, Hang Xu, Zhen Yang, Chaoqiang Ye, Yanwei Fu, Michael Bi Mi, Li Zhang
<br> CVPR 2022
[<a href="https://once-3dlanes.github.io" target="_blank">project page</a>]
</li> 


<li> <span class="papertitle">SGM3D: Stereo Guided Monocular 3D Object Detection,</span>
<br> Zheyuan Zhou, Liang Du, Xiaoqing Ye, Zhikang Zou, Xiao Tan, Errui Ding, Li Zhang, Xiangyang Xue, Jianfeng Feng,
<br> IEEE Robotics and Automation Letters (RAL) 2022,
[<a href="https://arxiv.org/abs/2112.01914" target="_blank">paper</a>]
</li> 


<li> <span class="papertitle">SOFT: Softmax-free Transformer with Linear Complexity,</span>
<br> Jiachen Lu, Jinghan Yao, Junge Zhang, Xiatian Zhu, Hang Xu, Weiguo Gao, Chunjing Xu, Tao Xiang, Li Zhang,
<br> NeurIPS 2021 <span class="distinction">(Spotlight)</span> 
[<a href="https://github.com/fudan-zvg/SOFT" target="_blank">code</a>]
</li> 

<li> <span class="papertitle">Progressive Coordinate Transforms for Monocular 3D Object Detection,</span>
<br> Li Wang, Li Zhang, Yi Zhu, Zhi Zhang, Tong He, Mu Li, Xiangyang Xue,
<br> NeurIPS 2021
[<a href="https://github.com/amazon-research/progressive-coordinate-transforms" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">The Devil is in the Task: Exploiting Reciprocal Appearance-Localization Features for Monocular 3D Object Detection,</span>
<br> Zhikang Zou, Xiaoqing Ye, Liang Du, Xianhui Cheng, Xiao Tan, Li Zhang, Jianfeng Feng, Xiangyang Xue, Errui Ding,
<br> ICCV 2021
</li> 

<li> <span class="papertitle">Simpler is Better: Few-shot Semantic Segmentation with Classifier Weight Transformer,</span>
<br> Zhihe Lu, Sen He, Xiatian Zhu, Li Zhang, Yi-Zhe Song, Tao Xiang,
<br> ICCV 2021
[<a href="https://github.com/zhiheLu/CWT-for-FSS" target="_blank">code</a>]
</li> 

<li> <span class="papertitle">Boundary-sensitive Pretraining for Temporal Localization in Videos,</span>
<br> Mengmeng Xu, Victor Escorcia, Brais Mart√≠nez, Juan-Manuel Perez-Rua, Xiatian Zhu, Li Zhang, Bernard Ghanem, Tao Xiang,
<br> ICCV 2021
</li> 

<li> <span class="papertitle">Text-Based Person Search with Limited Data,</span>
<br> Xiao Han, Sen He, Li Zhang, Tao Xiang,
<br> BMVC 2021
</li> 

<li> <span class="papertitle">Few-shot Action Recognition with Prototype-centered Attentive Learning,</span>
<br> Xiatian Zhu, Antoine Toisoul, Juan-Manuel Prez-Ra, Li Zhang, Brais Martinez, Tao Xiang,
<br> BMVC 2021
</li> 


<li> <span class="papertitle">Rethinking Local and Global Feature Representation for Semantic Segmentation,</span>
<br> Mohan Chen, Xinxuan Zhao, Bingfei Fu, Li Zhang, Xiangyang Xue,
<br> BMVC 2021
</li> 

<li> <span class="papertitle">Dual Prior Learning for Blind and Blended Image Restoration,</span>
<br> Xin Jin, Li Zhang, Chaowei Shan, Xin Li, Zhibo Chen,
<br> IEEE TIP 2021
</li> 


<li> <span class="papertitle">Towards Efficient Scene Understanding via Squeeze Reasoning,</span>
<br> Xiangtai Li, Xia Li, Ansheng You, Li Zhang, Guangliang Cheng, Kuiyuan Yang, Yunhai Tong, Zhouchen Lin,
<br> IEEE TIP 2021
[<a href="https://github.com/lxtGH/SFSegNets1" target="_blank">code</a>]
</li> 

<li> <span class="papertitle">Global Aggregation then Local Distribution for Scene Parsing,</span>
<br> Xiangtai Li, Li Zhang, Guangliang Cheng, Kuiyuan Yang, Yunhai Tong, Xiatian Zhu, Tao Xiang,
<br> IEEE TIP 2021
[<a href="https://github.com/lxtGH/GALD-DGCNet" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">How to trust unlabeled data? Instance Credibility Inference for Few-Shot Learning,</span>
<br> Yikai Wang, Li Zhang, Yuan Yao, Yanwei Fu
<br> TPAMI 2021
[<a href="https://arxiv.org/pdf/2007.08461" target="_blank">paper</a>]
[<a href="https://github.com/Yikai-Wang/ICI-FSL" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers,</span>
<br> Sixiao Zheng, Jiachen Lu, Hengshuang Zhao, Xiatian Zhu, Zekun Luo, Yabiao Wang, Yanwei Fu, Jianfeng Feng, Tao Xiang, Philip HS Torr, Li Zhang
<br> CVPR 2021
[<a href="https://arxiv.org/abs/2012.15840" target="_blank">paper</a>]
[<a href="https://github.com/fudan-zvg/SETR" target="_blank">code</a>]
</li> 

<li> <span class="papertitle">Depth-conditioned Dynamic Message Propagation for Monocular 3D Object Detection,</span>
<br> Li Wang, Liang Du, Xiaoqing Ye, Yanwei Fu, Guodong Guo, Xiangyang Xue, Jianfeng Feng, Li Zhang
<br> CVPR 2021
[<a href="https://arxiv.org/abs/2103.16470" target="_blank">paper</a>]
[<a href="https://github.com/fudan-zvg/DDMP" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">Learning Dynamic Alignment via Meta-filter for Few-shot Learning,</span>
<br> Chengming Xu, Yanwei Fu, Chen Liu, Chengjie Wang, Jilin Li, Feiyue Huang, Li Zhang, Xiangyang Xue, 
<br> CVPR 2021
[<a href="https://github.com/loadder/Dynamic-Meta-filter" target="_blank">code</a>]
</li> 

<li> <span class="papertitle">Delving into Data: Effectively Substitute Training for Black-box Attack,</span>
<br> Wenxuan Wang, Bangjie Yin, Taiping Yao, Li Zhang, Yanwei Fu, Shouhong Ding, Jilin Li, Feiyue Huang, Xiangyang Xue
<br> CVPR 2021
</li> 


<li> <span class="papertitle">Learning a Few-shot Embedding Model with Contrastive Learning,</span>
<br> Chen Liu, Yanwei Fu, Chengming Xu, Siqian Yang, Jilin Li, Chengjie Wang, Li Zhang
<br> AAAI 2021
[<a href="https://github.com/corwinliu9669/Learning-a-Few-shot-Embedding-Model-with-Contrastive-Learning" target="_blank">code</a>]
</li> 



<li> <span class="papertitle">Long-Term Cloth-Changing Person Re-identification,</span>
<br> Xuelin Qian, Wenxuan Wang, Li Zhang, Fangrui Zhu, Yanwei Fu, Tao Xiang, Yu-Gang Jiang, Xiangyang Xue
<br> ACCV 2020 <span class="distinction">(Oral)</span> 
[<a href="https://arxiv.org/abs/2005.12633" target="_blank">paper</a>]
[<a href="https://naiq.github.io/LTCC_Perosn_ReID.html" target="_blank">project page</a>]
</li> 


<li> <span class="papertitle">Dynamic Depth Fusion and Transformation for Monocular 3D Object Detection,</span>
<br> Erli Ouyang*, Li Zhang*, Mohan Chen, Anurag Arnab, Yanwei Fu
<br> ACCV 2020
[<a href="https://openaccess.thecvf.com/content/ACCV2020/papers/Ouyang_Dynamic_Depth_Fusion_and_Transformation_for_Monocular_3D_Object_Detection_ACCV_2020_paper.pdf" target="_blank">paper</a>]
</li> 


<li> <span class="papertitle">Depth Guided Adaptive Meta-Fusion Network for Few-shot Video Recognition,</span>
<br> Yuqian Fu*, Li Zhang*, Junke Wang, Yanwei Fu, Yu-Gang Jiang
<br> ACM MM 2020 <span class="distinction">(Oral)</span> 
[<a href="https://arxiv.org/abs/2010.09982" target="_blank">paper</a>]
</li> 

<li> <span class="papertitle">Few-shot Action Recognition with Permutation-invariant Attention,</span>
<br> Hongguang Zhang, Li Zhang, Xiaojuan Qi, Hongdong Li, Philip H.S. Torr, Piotr Koniusz
<br> ECCV 2020 <span class="distinction">(Spotlight)</span> 
[<a href="https://arxiv.org/abs/2001.03905" target="_blank">paper</a>]
</li> 


<li> <span class="papertitle">XingGAN for Person Image Generation,</span>
<br> Hao Tang, Song Bai, Li Zhang, Philip H.S. Torr, Nicu Sebe
<br> ECCV 2020
[<a href="https://arxiv.org/abs/2007.09278" target="_blank">paper</a>]
[<a href="https://github.com/Ha0Tang/XingGAN" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">Improving Semantic Segmentation via Decoupled Body and Edge Supervision,</span>
<br> Xiangtai Li, Xia Li, Li Zhang, Guangliang Cheng, Jianping Shi, Zhouchen Lin, Shaohua Tan, Yunhai Tong
<br> ECCV 2020
[<a href="https://arxiv.org/abs/2007.10035" target="_blank">paper</a>]
[<a href="https://github.com/lxtGH/DecoupleSegNets" target="_blank">code</a>]
</li> 

<li> <span class="papertitle">Dynamic Graph Message Passing Network,</span>
<br> Li Zhang, Dan Xu, Anurag Arnab, Philip H.S. Torr
<br> CVPR 2020 <span class="distinction">(Oral)</span> 
[<a href="https://arxiv.org/abs/1908.06955" target="_blank">paper</a>]
[<a href="https://github.com/lzrobots/dgmn" target="_blank">code</a>]
</li> 

<li> <span class="papertitle">Strip Pooling: Rethinking Spatial Pooling for Scene Parsing,</span>
<br> Qibin Hou, Li Zhang, Ming-Ming Cheng, Jiashi Feng
<br> CVPR 2020
[<a href="https://arxiv.org/abs/2003.13328" target="_blank">paper</a>]
[<a href="https://github.com/Andrew-Qibin/SPNet" target="_blank">code</a>]
</li> 

<li> <span class="papertitle">Instance Credibility Inference for Few-Shot Learning,</span>
<br> Yikai Wang, Chengming Xu, Chen Liu, Li Zhang, Yanwei Fu
<br> CVPR 2020 
[<a href="https://arxiv.org/abs/2003.11853" target="_blank">paper</a>]
[<a href="https://github.com/Yikai-Wang/ICI-FSL" target="_blank">code</a>]
</li> 

<li> <span class="papertitle">Style Normalization and Restitution for Generalizable Person Re-identification,</span>
<br> Xin Jin, Cuiling Lan, Wenjun Zeng, Zhibo Chen, Li Zhang
<br> CVPR 2020 
[<a href="https://arxiv.org/abs/2005.11037" target="_blank">paper</a>]
</li> 


<li> <span class="papertitle">Dual Graph Convolutional Network for Semantic Segmentation,</span>
<br> Li Zhang, Xiangtai Li, Anurag Arnab, Kuiyuan Yang, Yunhai Tong, Philip H.S. Torr
<br> BMVC 2019 
[<a href="https://arxiv.org/abs/1909.06121" target="_blank">paper</a>]
[<a href="https://github.com/lxtGH/GALD-Net" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">Global Aggregation then Local Distribution in Fully Convolutional Networks,</span>
<br> Xiangtai Li, Li Zhang, Ansheng You, Maoke Yang, Kuiyuan Yang, Yunhai Tong
<br> BMVC 2019 
[<a href="https://arxiv.org/abs/1909.07229" target="_blank">paper</a>]
[<a href="https://github.com/lxtGH/GALD-Net" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">Fast Online Object Tracking and Segmentation: A Unifying Approach,</span>
<br> Qiang Wang*, Li Zhang*, Luca Bertinetto*, Weiming Hu, Philip H.S. Torr
<br> CVPR 2019 
[<a href="https://arxiv.org/abs/1812.05050" target="_blank">paper</a>]
[<a href="https://github.com/foolwood/SiamMask" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">Learning to Compare: Relation Network for Few-Shot Learning,</span>
<br> Flood Sung, Yongxin Yang, Li Zhang, Tao Xiang, Philip H.S. Torr, Timothy M. Hospedales
<br> CVPR 2018
[<a href="https://arxiv.org/abs/1711.06025" target="_blank">paper</a>]
[<a href="https://github.com/songrotek/LearningToCompare_FSL" target="_blank">FSL code</a>]
[<a href="https://github.com/lzrobots/LearningToCompare_ZSL" target="_blank">ZSL code</a>]
</li> 


<li> <span class="papertitle">Learning a Deep Embedding Model for Zero-Shot Learning,</span>
<br> Li Zhang, Tao Xiang, Shaogang Gong
<br> CVPR 2017
[<a href="https://arxiv.org/abs/1611.05088" target="_blank">paper</a>]
[<a href="https://github.com/lzrobots/DeepEmbeddingModel_ZSL" target="_blank">code</a>]
</li> 


<li> <span class="papertitle">Learning a Discriminative Null Space for Person Re-identification,</span>
<br> Li Zhang, Tao Xiang, Shaogang Gong
<br> CVPR 2016
[<a href="http://arxiv.org/abs/1603.02139" target="_blank">paper</a>]
[<a href="https://github.com/lzrobots/NullSpace_ReID" target="_blank">code</a>]
</li> 

</ul> </div> 


<hr><div id="footer" class="row-footer"> 
<p>
&copy; <a href="https://lzrobots.github.io">Li Zhang</a> 2018-2023.
Based on a design by <a href="http://www.robots.ox.ac.uk/~namhoon/">Namhoon Lee</a>.
</p>
</div> 


</div>
</body> 
</html>






